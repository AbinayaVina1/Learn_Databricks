# Databricks Notebook for Azure Blob Storage Integration and CSV Analysis

This repository contains a Databricks notebook designed to demonstrate integration with Azure Blob Storage and loading of CSV files for data analysis using PySpark. Below is a step-by-step guide for replicating the functionality.

---

## Features
- Mounting Azure Blob Storage into Databricks
- Reading CSV files using PySpark
- Displaying and analyzing data using DataFrame operations

---

## Prerequisites
1. **Databricks Workspace**: Ensure you have access to a Databricks workspace.
2. **Azure Blob Storage**: Have an Azure Blob Storage container available with the required data files.
3. **Secrets Configuration**: Store your Azure account access key in Databricks Secrets to securely authenticate with Azure.

---
